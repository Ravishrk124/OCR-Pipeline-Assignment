{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Pipeline Assignment – Handwritten Document PII Extraction\n",
    "\n",
    "## Complete End-to-End Pipeline\n",
    "\n",
    "**Objective**: Build a comprehensive OCR + PII extraction pipeline for handwritten documents\n",
    "\n",
    "**Pipeline Flow**:\n",
    "1. Input (handwritten JPEG)\n",
    "2. Pre-processing (rotation correction, noise reduction, contrast enhancement)\n",
    "3. OCR (text extraction using Tesseract)\n",
    "4. Text Cleaning (error correction, normalization)\n",
    "5. PII Detection (names, phone numbers, emails, dates, addresses, medical IDs)\n",
    "6. Redacted Image Generation (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, ensure all dependencies are installed. Run the following commands in your terminal:\n",
    "\n",
    "```bash\n",
    "# Install Python dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Download spaCy model\n",
    "python -m spacy download en_core_web_sm\n",
    "\n",
    "# Install Tesseract OCR (system dependency)\n",
    "# macOS: brew install tesseract\n",
    "# Ubuntu: sudo apt-get install tesseract-ocr\n",
    "# Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "# Import our custom modules\n",
    "from preprocessing import preprocess_pipeline, visualize_preprocessing_steps\n",
    "from ocr_engine import extract_text, extract_with_boxes, ocr_pipeline, get_ocr_confidence\n",
    "from text_cleaner import clean_pipeline, get_cleaning_stats\n",
    "from pii_detector import detect_all_pii, highlight_pii_in_text, get_pii_summary, setup_spacy_model\n",
    "from redactor import generate_redacted_image, create_comparison_image, map_text_to_coordinates\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✅ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-load spaCy model (this might take a moment the first time)\n",
    "print(\"Loading spaCy model...\")\n",
    "nlp = setup_spacy_model()\n",
    "print(\"✅ spaCy model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Display Sample Images\n",
    "\n",
    "Let's load the three sample handwritten documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample image paths\n",
    "sample_images = [\n",
    "    '../Sample/page_14.jpg',\n",
    "    '../Sample/page_30.jpg',\n",
    "    '../Sample/page_35.jpg'\n",
    "]\n",
    "\n",
    "# Display all sample images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "fig.suptitle('Sample Handwritten Documents', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, img_path in enumerate(sample_images):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[idx].imshow(img_rgb)\n",
    "    axes[idx].set_title(f'Sample {idx + 1}: {os.path.basename(img_path)}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/00_original_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Loaded {len(sample_images)} sample images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Pre-processing\n",
    "\n",
    "Pre-processing steps to enhance image quality for better OCR:\n",
    "- **Deskewing**: Correct tilted/rotated images\n",
    "- **Denoising**: Reduce noise while preserving edges\n",
    "- **Contrast Enhancement**: Apply CLAHE for better text visibility\n",
    "- **Binarization**: Convert to black & white for clearer text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate preprocessing on first sample\n",
    "print(\"Demonstrating preprocessing pipeline on Sample 1...\\n\")\n",
    "results, fig = visualize_preprocessing_steps(sample_images[0])\n",
    "plt.savefig('../results/01_preprocessing_steps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Preprocessing demonstration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all samples and save\n",
    "print(\"Preprocessing all sample images...\\n\")\n",
    "\n",
    "preprocessed_images = {}\n",
    "\n",
    "for img_path in tqdm(sample_images, desc=\"Preprocessing\"):\n",
    "    base_name = os.path.basename(img_path).replace('.jpg', '')\n",
    "    output_path = f'../outputs/preprocessed/{base_name}_preprocessed.jpg'\n",
    "    \n",
    "    # Run preprocessing pipeline\n",
    "    result = preprocess_pipeline(img_path, save_path=output_path)\n",
    "    preprocessed_images[base_name] = result\n",
    "    \n",
    "    print(f\"  ✓ Saved: {output_path}\")\n",
    "\n",
    "print(\"\\n✅ All images preprocessed and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OCR - Text Extraction\n",
    "\n",
    "Extract text from preprocessed images using Tesseract OCR with LSTM models optimized for handwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from all samples\n",
    "print(\"Extracting text using OCR...\\n\")\n",
    "\n",
    "ocr_results = {}\n",
    "\n",
    "for img_path in tqdm(sample_images, desc=\"OCR Processing\"):\n",
    "    base_name = os.path.basename(img_path).replace('.jpg', '')\n",
    "    \n",
    "    # Use preprocessed binary image for OCR\n",
    "    binary_image = preprocessed_images[base_name]['binary']\n",
    "    \n",
    "    # Extract text with boxes and confidence\n",
    "    result = ocr_pipeline(binary_image, extract_boxes=True, get_confidence=True)\n",
    "    ocr_results[base_name] = result\n",
    "    \n",
    "    # Save extracted text\n",
    "    output_path = f'../outputs/ocr_results/{base_name}_extracted_text.txt'\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(result['text'])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample: {base_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Extracted Text:\\n{result['text'][:300]}...\")\n",
    "    print(f\"\\nConfidence Stats:\")\n",
    "    print(f\"  - Mean: {result['confidence']['mean_confidence']:.2f}%\")\n",
    "    print(f\"  - Median: {result['confidence']['median_confidence']:.2f}%\")\n",
    "    print(f\"  - Word Count: {result['confidence']['word_count']}\")\n",
    "\n",
    "print(\"\\n✅ OCR extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Cleaning\n",
    "\n",
    "Clean and normalize OCR output:\n",
    "- Remove noise characters and OCR artifacts\n",
    "- Correct common OCR errors (O↔0, l↔I, etc.)\n",
    "- Standardize whitespace and formatting\n",
    "- Normalize dates and phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extracted text\n",
    "print(\"Cleaning extracted text...\\n\")\n",
    "\n",
    "cleaned_texts = {}\n",
    "\n",
    "for base_name, ocr_result in ocr_results.items():\n",
    "    original_text = ocr_result['text']\n",
    "    cleaned_text = clean_pipeline(original_text)\n",
    "    cleaned_texts[base_name] = cleaned_text\n",
    "    \n",
    "    # Get cleaning stats\n",
    "    stats = get_cleaning_stats(original_text, cleaned_text)\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Sample: {base_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Cleaning Stats:\")\n",
    "    print(f\"  - Original length: {stats['original_length']} characters\")\n",
    "    print(f\"  - Cleaned length: {stats['cleaned_length']} characters\")\n",
    "    print(f\"  - Characters removed: {stats['characters_removed']}\")\n",
    "    print(f\"  - Word count: {stats['original_words']} → {stats['cleaned_words']}\")\n",
    "    print(f\"\\nCleaned Text Preview:\\n{cleaned_text[:300]}...\\n\")\n",
    "\n",
    "print(\"✅ Text cleaning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PII Detection\n",
    "\n",
    "Detect all Personally Identifiable Information (PII):\n",
    "- **PERSON**: Names\n",
    "- **PHONE**: Phone numbers (multiple formats)\n",
    "- **EMAIL**: Email addresses\n",
    "- **DATE**: Dates (DOB, appointment dates)\n",
    "- **ADDRESS**: Physical addresses, locations\n",
    "- **MEDICAL_ID**: Patient IDs, medical record numbers\n",
    "- **ORG**: Organizations (hospitals, clinics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect PII in all samples\n",
    "print(\"Detecting PII in extracted text...\\n\")\n",
    "\n",
    "pii_results = {}\n",
    "\n",
    "for base_name, cleaned_text in cleaned_texts.items():\n",
    "    # Detect all PII\n",
    "    pii_data = detect_all_pii(cleaned_text)\n",
    "    pii_results[base_name] = pii_data\n",
    "    \n",
    "    # Save PII detection results as JSON\n",
    "    output_path = f'../outputs/pii_detected/{base_name}_pii.json'\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(pii_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Sample: {base_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(get_pii_summary(pii_data))\n",
    "    print()\n",
    "\n",
    "print(\"✅ PII detection complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PII detection with highlighted text\n",
    "print(\"Creating PII-highlighted text visualizations...\\n\")\n",
    "\n",
    "for base_name, pii_data in pii_results.items():\n",
    "    highlighted_text = highlight_pii_in_text(cleaned_texts[base_name], pii_data, highlight_char='█')\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Sample: {base_name} - Text with PII Redacted\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(highlighted_text[:500])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PII Detection Statistics and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics DataFrame\n",
    "summary_data = []\n",
    "\n",
    "for base_name, pii_data in pii_results.items():\n",
    "    row = {'Sample': base_name, 'Total PII': pii_data['pii_count']}\n",
    "    row.update(pii_data['pii_types'])\n",
    "    summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nPII Detection Summary:\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_df.to_csv('../outputs/pii_detected/summary_statistics.csv', index=False)\n",
    "print(\"\\n✅ Summary statistics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PII distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Chart 1: Total PII by sample\n",
    "samples = [row['Sample'] for row in summary_data]\n",
    "totals = [row['Total PII'] for row in summary_data]\n",
    "axes[0].bar(samples, totals, color='steelblue')\n",
    "axes[0].set_title('Total PII Entities per Sample', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sample')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Chart 2: PII type distribution (stacked)\n",
    "pii_types = ['PERSON', 'PHONE', 'EMAIL', 'DATE', 'ADDRESS', 'MEDICAL_ID', 'ORG']\n",
    "type_data = {pii_type: [row[pii_type] for row in summary_data] for pii_type in pii_types}\n",
    "\n",
    "x = np.arange(len(samples))\n",
    "width = 0.6\n",
    "bottom = np.zeros(len(samples))\n",
    "\n",
    "colors = ['#e74c3c', '#3498db', '#f39c12', '#2ecc71', '#9b59b6', '#1abc9c', '#e67e22']\n",
    "\n",
    "for idx, pii_type in enumerate(pii_types):\n",
    "    values = type_data[pii_type]\n",
    "    axes[1].bar(x, values, width, label=pii_type, bottom=bottom, color=colors[idx])\n",
    "    bottom += values\n",
    "\n",
    "axes[1].set_title('PII Type Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Sample')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(samples)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/02_pii_statistics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ PII statistics visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image Redaction (Optional)\n",
    "\n",
    "Generate redacted versions of the original images with PII obscured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate redacted images for all samples\n",
    "print(\"Generating redacted images...\\n\")\n",
    "\n",
    "redaction_results = {}\n",
    "\n",
    "for idx, img_path in enumerate(tqdm(sample_images, desc=\"Redacting\")):\n",
    "    base_name = os.path.basename(img_path).replace('.jpg', '')\n",
    "    \n",
    "    # Get PII data\n",
    "    pii_data = pii_results[base_name]\n",
    "    \n",
    "    # Generate redacted image (black boxes)\n",
    "    output_path = f'../outputs/redacted/{base_name}_redacted.jpg'\n",
    "    result = generate_redacted_image(img_path, pii_data, output_path, redaction_type='black')\n",
    "    \n",
    "    # Also generate labeled version for visualization\n",
    "    labeled_output = f'../outputs/redacted/{base_name}_labeled.jpg'\n",
    "    labeled_result = generate_redacted_image(img_path, pii_data, labeled_output, redaction_type='labeled')\n",
    "    \n",
    "    redaction_results[base_name] = {\n",
    "        'black': result,\n",
    "        'labeled': labeled_result\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ {base_name}: {result['entities_redacted']} entities redacted\")\n",
    "\n",
    "print(\"\\n✅ Image redaction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display redaction results (labeled version for visibility)\n",
    "fig, axes = plt.subplots(len(sample_images), 2, figsize=(16, 6 * len(sample_images)))\n",
    "fig.suptitle('Redaction Results - Original vs Labeled PII', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, img_path in enumerate(sample_images):\n",
    "    base_name = os.path.basename(img_path).replace('.jpg', '')\n",
    "    \n",
    "    # Original\n",
    "    original = redaction_results[base_name]['labeled']['original']\n",
    "    axes[idx, 0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 0].set_title(f'{base_name} - Original')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    # Labeled redacted\n",
    "    redacted = redaction_results[base_name]['labeled']['redacted']\n",
    "    axes[idx, 1].imshow(cv2.cvtColor(redacted, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 1].set_title(f'{base_name} - PII Labeled ({redaction_results[base_name][\"labeled\"][\"entities_redacted\"]} entities)')\n",
    "    axes[idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/03_redaction_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Pipeline Demo\n",
    "\n",
    "Demonstrate the entire pipeline on a single sample from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_pipeline(image_path, output_dir='../outputs'):\n",
    "    \"\"\"\n",
    "    Run the complete OCR + PII extraction pipeline.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to input image\n",
    "        output_dir (str): Directory for outputs\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete pipeline results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Running Complete Pipeline: {os.path.basename(image_path)}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Preprocessing\n",
    "    print(\"[1/6] Preprocessing image...\")\n",
    "    preprocessed = preprocess_pipeline(image_path)\n",
    "    results['preprocessed'] = preprocessed\n",
    "    print(\"  ✓ Image preprocessed\")\n",
    "    \n",
    "    # Step 2: OCR\n",
    "    print(\"[2/6] Extracting text with OCR...\")\n",
    "    ocr_result = ocr_pipeline(preprocessed['binary'], extract_boxes=True, get_confidence=True)\n",
    "    results['ocr'] = ocr_result\n",
    "    print(f\"  ✓ Extracted {len(ocr_result['text'])} characters\")\n",
    "    print(f\"  ✓ Mean confidence: {ocr_result['confidence']['mean_confidence']:.2f}%\")\n",
    "    \n",
    "    # Step 3: Text Cleaning\n",
    "    print(\"[3/6] Cleaning text...\")\n",
    "    cleaned_text = clean_pipeline(ocr_result['text'])\n",
    "    results['cleaned_text'] = cleaned_text\n",
    "    stats = get_cleaning_stats(ocr_result['text'], cleaned_text)\n",
    "    print(f\"  ✓ Removed {stats['characters_removed']} noise characters\")\n",
    "    \n",
    "    # Step 4: PII Detection\n",
    "    print(\"[4/6] Detecting PII...\")\n",
    "    pii_data = detect_all_pii(cleaned_text)\n",
    "    results['pii'] = pii_data\n",
    "    print(f\"  ✓ Detected {pii_data['pii_count']} PII entities\")\n",
    "    for pii_type, count in pii_data['pii_types'].items():\n",
    "        if count > 0:\n",
    "            print(f\"    - {pii_type}: {count}\")\n",
    "    \n",
    "    # Step 5: Generate Redacted Image\n",
    "    print(\"[5/6] Generating redacted image...\")\n",
    "    redacted_result = generate_redacted_image(image_path, pii_data, redaction_type='labeled')\n",
    "    results['redacted'] = redacted_result\n",
    "    print(f\"  ✓ Redacted {redacted_result['entities_redacted']} entities\")\n",
    "    \n",
    "    # Step 6: Summary\n",
    "    print(\"[6/6] Pipeline complete!\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run complete pipeline on first sample\n",
    "demo_results = complete_pipeline(sample_images[0])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Characters Extracted: {len(demo_results['ocr']['text'])}\")\n",
    "print(f\"OCR Confidence: {demo_results['ocr']['confidence']['mean_confidence']:.2f}%\")\n",
    "print(f\"Total PII Detected: {demo_results['pii']['pii_count']}\")\n",
    "print(f\"Entities Redacted: {demo_results['redacted']['entities_redacted']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export All Results\n",
    "\n",
    "Export comprehensive results for all samples in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "comprehensive_results = []\n",
    "\n",
    "for base_name in pii_results.keys():\n",
    "    comprehensive_results.append({\n",
    "        'sample_name': base_name,\n",
    "        'ocr_text': ocr_results[base_name]['text'],\n",
    "        'cleaned_text': cleaned_texts[base_name],\n",
    "        'ocr_confidence': ocr_results[base_name]['confidence'],\n",
    "        'pii_detection': pii_results[base_name],\n",
    "        'redaction_stats': {\n",
    "            'entities_redacted': redaction_results[base_name]['black']['entities_redacted']\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Save comprehensive results\n",
    "output_file = '../outputs/comprehensive_results.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(comprehensive_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Comprehensive results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Results Summary\n",
    "\n",
    "**Pipeline Performance Summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*25 + \"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for base_name in pii_results.keys():\n",
    "    print(f\"Sample: {base_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  OCR Confidence:        {ocr_results[base_name]['confidence']['mean_confidence']:.2f}%\")\n",
    "    print(f\"  Words Extracted:       {ocr_results[base_name]['confidence']['word_count']}\")\n",
    "    print(f\"  PII Entities Found:    {pii_results[base_name]['pii_count']}\")\n",
    "    print(f\"  Entities Redacted:     {redaction_results[base_name]['black']['entities_redacted']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✅ PIPELINE EXECUTION COMPLETE!\\n\")\n",
    "print(\"Outputs saved to:\")\n",
    "print(\"  - Preprocessed images:  outputs/preprocessed/\")\n",
    "print(\"  - OCR text files:       outputs/ocr_results/\")\n",
    "print(\"  - PII detection JSON:   outputs/pii_detected/\")\n",
    "print(\"  - Redacted images:      outputs/redacted/\")\n",
    "print(\"  - Result screenshots:   results/\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates a complete end-to-end OCR + PII extraction pipeline for handwritten documents. The pipeline successfully:\n",
    "\n",
    "1. ✅ **Pre-processes** images to handle tilted documents and improve quality\n",
    "2. ✅ **Extracts text** from handwritten documents using Tesseract OCR\n",
    "3. ✅ **Cleans text** to correct common OCR errors\n",
    "4. ✅ **Detects PII** across 7 categories (names, phones, emails, dates, addresses, medical IDs, organizations)\n",
    "5. ✅ **Generates redacted images** with PII obscured\n",
    "\n",
    "### Key Features:\n",
    "- Modular, reusable code architecture\n",
    "- Handles tilted images and various handwriting styles\n",
    "- Comprehensive PII detection with confidence scores\n",
    "- Multiple redaction visualization options\n",
    "- Complete JSON output for integration\n",
    "\n",
    "### Benchmarking Note:\n",
    "To test with new documents, simply:\n",
    "1. Place new images in a folder\n",
    "2. Update the `sample_images` list\n",
    "3. Re-run all cells\n",
    "\n",
    "The pipeline is production-ready and can be integrated into larger systems via the modular Python modules in the `src/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
